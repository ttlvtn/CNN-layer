import streamlit as st
import torch
from torchvision import models, transforms
from PIL import Image, ImageFilter
import requests
import numpy as np

# é é¢è¨­å®š
st.set_page_config(page_title="AI å½±åƒå°ˆå®¶ç³»çµ±", layout="wide")

# --- 1. æ ¸å¿ƒå¤§è…¦ï¼šè¼‰å…¥æ¨¡å‹ ---
@st.cache_resource
def get_resources():
    # è¼‰å…¥ ResNet-101 (æ·±åº¦èˆ‡ç©©å®šä»£è¡¨)
    res101 = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V1)
    res101.eval()
    # è¼‰å…¥ EfficientNet-B0 (æ•ˆç‡èˆ‡ç²¾æº–ä»£è¡¨)
    eff_b0 = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)
    eff_b0.eval()
    # è¼‰å…¥åˆ†é¡æ¨™ç±¤
    response = requests.get("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt")
    labels = response.text.split("\n")
    return res101, eff_b0, labels

res101, eff_b0, labels = get_resources()

# --- 2. ä»‹é¢æ¨™é¡Œ ---
st.title("ğŸ¤– AI å½±åƒæ¢éšªï¼šå¾ã€çœ‹è¦‹ç·šæ¢ã€åˆ°ã€ç†è§£ç‰©ä»¶ã€")
st.markdown("""
é€™å€‹ App æœƒå¸¶ä½ é€²å…¥ **CNN (å·ç©ç¥ç¶“ç¶²è·¯)** çš„éš±è—å±¤ä¸–ç•Œã€‚
æˆ‘å€‘æœƒå°æ¯”ç¶“å…¸çš„ **ResNet-101** èˆ‡ç¾ä»£çš„ **EfficientNet**ï¼Œçœ‹çœ‹å®ƒå€‘å¦‚ä½•ç†è§£ä½ ä¸Šå‚³çš„ç…§ç‰‡ã€‚
""")

# å´é‚Šæ¬„ï¼šæ•™å­¸è¨­å®š
with st.sidebar:
    st.header("ğŸ¢ å¯¦é©—å®¤è¨­å®š")
    model_choice = st.radio("é¸æ“‡ AI å¤§è…¦ï¼š", ["ResNet-101 (é‡è£æ·±å±¤)", "EfficientNet-B0 (è¼•é‡é«˜æ•ˆ)"])
    st.markdown("---")
    st.markdown("### æ¥­ç•Œå°ˆå®¶å°å®åš€")
    st.write("åœ¨æ¥­ç•Œï¼ŒResNet å¸¸ç”¨æ–¼**é†«ç™‚å½±åƒ**ï¼Œå› ç‚ºå®ƒæ¶æ§‹ç©©å®šï¼›EfficientNet å¸¸ç”¨æ–¼**æ‰‹æ©Ÿ App**ï¼Œå› ç‚ºå®ƒåˆå¿«åˆçœé›»ã€‚")

# --- 3. åœ–ç‰‡ä¸Šå‚³å€ ---
uploaded_file = st.file_uploader("ğŸ“¸ ä¸Šå‚³ä¸€å¼µç…§ç‰‡ä¾†æ¸¬è©¦ (ä¾‹å¦‚è²“ã€ç‹—ã€è»Šã€èŠ±...)", type=["jpg", "png", "jpeg"])

if uploaded_file:
    img = Image.open(uploaded_file).convert('RGB')
    
    # å‰è™•ç†è¦–è¦ºåŒ–
    col_input, col_ai_view = st.columns(2)
    with col_input:
        st.header("ğŸ“¥ ä½ çš„åŸå§‹ç…§ç‰‡")
        st.image(img, use_container_width=True)
    with col_ai_view:
        st.header("ğŸ‘“ AI çš„åˆæ­¥å°è±¡")
        # æ¨¡æ“¬ AI å‰è™•ç†ï¼šç¸®æ”¾ä¸¦ä¸­å¿ƒè£å‰ª
        ai_view = img.resize((224, 224))
        st.image(ai_view, caption="AI å¯¦éš›ä¸Šåªçœ‹é€™å¡Š 224x224 çš„å€åŸŸ", width=224)

    st.markdown("---")

    # --- 4. éš±è—å±¤è¦–è¦ºåŒ–ï¼šå‡¸é¡¯ç‰¹å¾µè™•ç†å«æ„ ---
    st.header(f"ğŸ—ï¸ {model_choice} çš„ç‰¹å¾µæå–éç¨‹")
    st.info("AI ä¸¦ä¸æ˜¯ç›´æ¥çœ‹åˆ°æ•´å¼µåœ–ï¼Œè€Œæ˜¯åœ¨éš±è—å±¤ä¸­é€²è¡Œã€ç‰¹å¾µéæ¿¾ã€ã€‚")

    v_col1, v_col2, v_col3 = st.columns(3)

    with v_col1:
        st.subheader("1. é‚Šç·£è™•ç† (Edges)")
        # è¦–è¦ºåŒ–æ¨¡æ“¬ï¼šä½¿ç”¨ FIND_EDGES æ¨¡æ“¬æ·ºå±¤å·ç©
        edge_map = img.convert('L').filter(ImageFilter.FIND_EDGES)
        st.image(edge_map, caption="æ·ºå±¤ï¼šåµæ¸¬è¼ªå»“èˆ‡ç·šæ¢", use_container_width=True)
        st.write("ğŸ” **AI åœ¨åšä»€éº¼ï¼Ÿ** å°‹æ‰¾ç‰©é«”çš„é‚Šç•Œã€æ¢ç´‹èˆ‡é¡è‰²äº¤ç•Œè™•ã€‚")

    with v_col2:
        st.subheader("2. ç‰¹å¾µè™•ç† (Shapes)")
        # è¦–è¦ºåŒ–æ¨¡æ“¬ï¼šå¼·åŒ–ç´°ç¯€ä¸¦ç¨å¾®æ¨¡ç³Šï¼Œæ¨¡æ“¬å±€éƒ¨ç‰¹å¾µåœ–
        feature_map = img.filter(ImageFilter.DETAIL).resize((img.width // 2, img.height // 2))
        st.image(feature_map, caption="ä¸­å±¤ï¼šèªå‡ºå½¢ç‹€é›¶ä»¶", use_container_width=True)
        st.write("ğŸ“ **AI åœ¨åšä»€éº¼ï¼Ÿ** å°‡ç·šæ¢çµ„åˆæˆä¸‰è§’å½¢ã€åœ“å½¢æˆ–ç´‹ç†ï¼Œèªå‡ºã€è€³æœµã€æˆ–ã€è¼ªå­ã€ã€‚")

    with v_col3:
        st.subheader("3. ç‰©ä»¶è™•ç† (Concepts)")
        # è¦–è¦ºåŒ–æ¨¡æ“¬ï¼šæ¥µåº¦åƒç´ åŒ–ï¼Œæ¨¡æ“¬é«˜éšæŠ½è±¡æ¬Šé‡
        concept_map = img.resize((14, 14)).resize((img.width, img.height), resample=Image.NEAREST)
        st.image(concept_map, caption="æ·±å±¤ï¼šç†è§£ç‰©ä»¶èªæ„", use_container_width=True)
        st.write("ğŸ§© **AI åœ¨åšä»€éº¼ï¼Ÿ** é€™æ˜¯æœ€æŠ½è±¡çš„éšæ®µï¼Œå®ƒåœ¨ç¢ºèªé€™äº›é›¶ä»¶çš„ç©ºé–“é—œä¿‚ï¼Œåˆ¤æ–·ã€é€™æ˜¯ä¸€éš»è²“ã€ã€‚")

    # --- 5. è¾¨è­˜çµæœ ---
    st.markdown("---")
    st.header("ğŸ† è¾¨è­˜æ±ºç­–éšæ®µ")
    
    # æ¨¡å‹é‹ç®—é è™•ç†
    preprocess = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    input_tensor = preprocess(img).unsqueeze(0)
    
    with st.spinner('æ­£åœ¨ç©¿è¶Š 101 å±¤éš±è—å±¤...'):
        model = res101 if "ResNet" in model_choice else eff_b0
        with torch.no_grad():
            output = model(input_tensor)
            prob = torch.nn.functional.softmax(output[0], dim=0)
            top5_prob, top5_id = torch.topk(prob, 5)

    res_col1, res_col2 = st.columns(2)
    with res_col1:
        st.subheader("ğŸ¯ çŒœæ¸¬çµæœ")
        for i in range(5):
            st.write(f"ç¬¬ {i+1} å: **{labels[top5_id[i]]}**")
    with res_col2:
        st.subheader("ğŸ“Š ä¿¡å¿ƒæŒ‡æ•¸")
        for i in range(5):
            st.progress(float(top5_prob[i]), text=f"{top5_prob[i]:.2%}")

    # --- 6. æ¥­ç•Œå¤§è§£å¯†ï¼šç‚ºä»€éº¼é€™å…©å€‹æ¨¡å‹å¾ˆå¼·ï¼Ÿ ---
    st.markdown("---")
    st.header("ğŸ¤ æ¥­ç•Œå¯¦æˆ°ï¼šåˆä½µä½¿ç”¨çš„è—è¡“")
    
    exp1, exp2 = st.columns(2)
    with exp1:
        st.markdown("### ğŸ¢ ResNet-101 çš„å¼·é …")
        st.write("**æ ¸å¿ƒï¼šè·³èºæ·å¾‘ (Skip Connection)**")
        st.write("å®ƒåƒæ˜¯ä¸€æ£Ÿçµæ§‹ç´®å¯¦çš„æ‘©å¤©å¤§æ¨“ã€‚å³ä½¿è“‹åˆ° 101 å±¤ï¼Œåªè¦æœ‰ã€å¿«é€Ÿé“è·¯ã€ï¼Œè¨Šæ¯å°±ä¸æœƒå‡ºéŒ¯ã€‚æ¥­ç•Œå¸¸ç”¨æ–¼éœ€è¦**çµ•å°ç©©å®š**çš„å ´æ™¯ï¼Œå¦‚å·¥æ¥­é›¶ä»¶æª¢æ¸¬ã€‚")
    with exp2:
        st.markdown("### âš¡ EfficientNet çš„å¼·é …")
        st.write("**æ ¸å¿ƒï¼šè¤‡åˆç¸®æ”¾ (Compound Scaling)**")
        st.write("å®ƒåƒæ˜¯ç²¾ç®—éå¾Œçš„è¶…ç´šè·‘è»Šã€‚ä¸ç›²ç›®è¿½æ±‚å±¤æ•¸ï¼Œè€Œæ˜¯è®“å¯¬åº¦èˆ‡è§£æåº¦é”åˆ°é»ƒé‡‘æ¯”ä¾‹ã€‚æ¥­ç•Œå¸¸ç”¨æ–¼**å¯¦æ™‚è¾¨è­˜**ï¼Œå¦‚ç›£è¦–å™¨æˆ–æ‰‹æ©Ÿ Appã€‚")

    st.success("ğŸ’¡ **æ¥­ç•Œè¶¨å‹¢ï¼š** ç¾åœ¨æœ€å²å®³çš„æŠ€è¡“æœƒå°‡å…©è€…ã€åˆä½µã€ã€‚ç”¨ ResNet çš„ç©©å®šç•¶éª¨å¹¹ï¼Œé…ä¸Š EfficientNet çš„ç¸®æ”¾é‚è¼¯ï¼Œæ‰“é€ å‡ºæ—¢æº–åˆå¿«çš„æ–°æ¨¡å‹ï¼ˆå¦‚ ConvNeXtï¼‰ï¼")
    
    st.balloons()
