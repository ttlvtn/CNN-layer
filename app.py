import streamlit as st
import numpy as np
from PIL import Image, ImageFilter, ImageOps
import matplotlib.pyplot as plt
import requests
import torch
from torchvision import models, transforms

# é é¢è¨­å®š
st.set_page_config(page_title="AI å¤§è…¦è§£å¯†ï¼šå¾ ANN åˆ° CNN", layout="wide")

# --- 1. æ¨¡å‹èˆ‡æ¨™ç±¤è¼‰å…¥ (ç”¨æ–¼ CNN æ¼”ç¤º) ---
@st.cache_resource
def get_cnn_resources():
    res101 = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V1)
    res101.eval()
    labels = requests.get("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt").text.split("\n")
    return res101, labels

resnet_model, imagenet_labels = get_cnn_resources()

# --- 2. ä»‹é¢æ¨™é¡Œ ---
st.title("ğŸ§  AI å¤§è…¦è§£å¯†ï¼šå¾ã€æ•¸å­—æ„Ÿã€åˆ°ã€ç©ºé–“æ„Ÿã€")
st.markdown("""
æˆ‘å€‘å°‡æ¢è¨å…©ç¨® AI å¤§è…¦ï¼š
1.  **ANN (äººå·¥ç¥ç¶“ç¶²è·¯)**ï¼šæœ€åŸºç¤çš„å¤§è…¦ï¼Œæ“…é•·è™•ç†æ•¸å­—è¡¨æ ¼ã€‚
2.  **CNN (å·ç©ç¥ç¶“ç¶²è·¯)**ï¼š**ANN çš„é€²åŒ–ç‰ˆ**ï¼Œå¢åŠ äº†ã€è¦–è¦ºã€èƒ½åŠ›ï¼Œå°ˆç‚ºåœ–åƒè¨­è¨ˆã€‚
""")

# --- 3. åœ–ç‰‡ä¸Šå‚³å€ ---
uploaded_file = st.file_uploader("ğŸ“¸ ä¸Šå‚³ä¸€å¼µåœ–ç‰‡ï¼Œæ¢ç´¢ AI çš„æ€è€ƒéç¨‹...", type=["jpg", "png", "jpeg"])

if uploaded_file:
    img = Image.open(uploaded_file).convert('RGB')
    
    st.image(img, caption="åŸå§‹è¼¸å…¥åœ–ç‰‡", use_container_width=True)
    st.markdown("---")

    col_ann_viz, col_cnn_viz = st.columns(2)

    # --- ANN çš„é‹ä½œé‚è¼¯èˆ‡è¦–è¦ºåŒ– ---
    with col_ann_viz:
        st.header("1. ANNï¼šã€æ•¸å­—å¤§é›œç‡´ã€")
        st.subheader("ç‰©ç†å«æ„ï¼š**è³‡è¨Šæ”¤å¹³èˆ‡åŠ æ¬ŠæŠ•ç¥¨**")
        st.write("ANN å°±åƒä¸€ç¾¤åªæœƒçœ‹æ•¸å­—çš„æœƒè¨ˆå¸«ã€‚å®ƒæœƒæŠŠåœ–ç‰‡çš„åƒç´ **å®Œå…¨æ”¤å¹³**æˆä¸€é•·ä¸²æ•¸å­—ï¼Œç„¶å¾Œæ¯å€‹æ•¸å­—éƒ½å»å½±éŸ¿ä¸‹ä¸€å±¤çš„æ¯å€‹ç¥ç¶“å…ƒã€‚")
        st.write("é€™æœƒè®“ AI å–ªå¤±åœ–ç‰‡çš„**ç©ºé–“æ„Ÿ**ï¼ˆä¸Šä¸‹å·¦å³é—œä¿‚ï¼‰ã€‚")

        # æ¨¡æ“¬ ANN çš„æ”¤å¹³èˆ‡å…¨é€£æ¥å±¤
        img_arr_gray = np.array(img.resize((50, 50)).convert('L')) # ç¸®å°ä¸¦è½‰ç°åº¦
        flattened_data = img_arr_gray.flatten() # æ”¤å¹³ç‚ºä¸€ç¶­
        
        fig_ann, ax_ann = plt.subplots(figsize=(6, 3))
        ax_ann.plot(flattened_data[:200], color='skyblue') # åªé¡¯ç¤ºå‰ 200 å€‹é»
        ax_ann.set_title("ANN çœ¼ä¸­çš„åœ–ç‰‡ (ä¸€ç¶­æ•¸å­—æµ)")
        ax_ann.set_xlabel("åƒç´ é»åºè™Ÿ")
        ax_ann.set_ylabel("åƒç´ äº®åº¦å€¼")
        st.pyplot(fig_ann)
        st.caption("AI çœ‹åˆ°çš„æ˜¯ä¸€ä¸²æ²’æœ‰ç©ºé–“æ„ç¾©çš„æ•¸å­—ï¼Œç„¶å¾Œé€éã€æ¬Šé‡ã€é€²è¡Œè¤‡é›œçš„åŠ æ¬ŠæŠ•ç¥¨ã€‚")

    # --- CNN çš„é‹ä½œé‚è¼¯èˆ‡è¦–è¦ºåŒ– ---
    with col_cnn_viz:
        st.header("2. CNNï¼šã€è¦–è¦ºåµæ¢ã€")
        st.subheader("ç‰©ç†å«æ„ï¼š**æ¿¾é¡æƒæèˆ‡å±€éƒ¨ç‰¹å¾µ**")
        st.write("CNN æ˜¯ **ANN çš„é€²åŒ–ç‰ˆ**ã€‚å®ƒåœ¨æœ€å‰é¢åŠ ä¸Šäº†**å·ç©å±¤ (Convolutional Layer)**ï¼Œå°±åƒçµ¦ AI è£ä¸Šäº†è¨±å¤šã€åµæ¢æ¿¾é¡ã€ã€‚")
        st.write("æ¯å€‹æ¿¾é¡å°ˆé–€è² è²¬åœ¨åœ–ç‰‡ä¸Šæƒæï¼Œå°‹æ‰¾ç‰¹å®šçš„å±€éƒ¨ç‰¹å¾µï¼ˆä¾‹å¦‚ï¼šé‚Šç·£ã€ç´‹ç†ã€å°å½¢ç‹€ï¼‰ã€‚")

        # æ¨¡æ“¬ CNN çš„å·ç©å±¤è™•ç† (é‚Šç·£æª¢æ¸¬)
        cnn_edge_view = img.convert('L').filter(ImageFilter.FIND_EDGES)
        st.image(cnn_edge_view, caption="CNN å‰åŠæ®µï¼šå·ç©å±¤æå–ã€é‚Šç·£ã€ç‰¹å¾µ", use_column_width=True)
        st.caption("å·ç©å±¤èƒ½å¤ ä¿ç•™åœ–ç‰‡çš„ã€ç©ºé–“æ„Ÿã€ï¼Œå®ƒçŸ¥é“ç·šæ¢åœ¨å“ªè£¡ã€‚")
        
        st.markdown("---")
        st.subheader("âœ¨ CNN çš„å¾ŒåŠæ®µï¼šé‚„æ˜¯ ANNï¼")
        st.write("åœ¨å·ç©å±¤æå–å®Œæ‰€æœ‰ç‰¹å¾µå¾Œï¼ŒCNN æœƒæŠŠé€™äº›**ç‰¹å¾µåœ–**ã€æ”¤å¹³ã€ï¼Œç„¶å¾Œé€å…¥å‚³çµ± ANN çš„**å…¨é€£æ¥å±¤ (Fully Connected Layer)** é€²è¡Œæœ€çµ‚çš„åˆ¤æ–·å’Œåˆ†é¡ã€‚")
        st.write("å¯ä»¥ç†è§£ç‚ºï¼š**CNN = ã€å·ç©åµæ¢çµ„ã€ + ã€ANN æŠ•ç¥¨éƒ¨éšŠã€**")

    st.markdown("---")

    # --- CNN æœ€çµ‚è¾¨è­˜çµæœ (ä½œç‚º CNN å¯¦éš›æ‡‰ç”¨çš„ä¾‹å­) ---
    st.header("ğŸ† CNN è¾¨è­˜çµæœ (ResNet-101 ç¤ºç¯„)")
    st.info("ResNet-101 æ˜¯ä¸€å€‹è¶…ç´šå¼·å¤§çš„ CNNï¼Œå®ƒæœ‰è¶…é 100 å±¤å·ç©å±¤ä¾†æå–ç‰¹å¾µï¼Œæœ€å¾Œå†ç”¨ ANN åˆ¤æ–·ã€‚")
    
    preprocess = transforms.Compose([
        transforms.Resize(256), transforms.CenterCrop(224),
        transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    input_tensor = preprocess(img).unsqueeze(0)
    
    with torch.no_grad():
        output = resnet_model(input_tensor)
        prob = torch.nn.functional.softmax(output[0], dim=0)
        top_prob, top_id = torch.topk(prob, 1)

    st.success(f"çµæœï¼š**{imagenet_labels[top_id[0]]}** (ä¿¡å¿ƒæŒ‡æ•¸ï¼š{top_prob[0]:.2%})")
    
    st.markdown("---")
    st.subheader("ç¸½çµï¼šAI çš„é€²åŒ–ä¹‹è·¯")
    st.write("""
    - **ANN** å­¸ç¿’æ•¸å­—æ¨¡å¼ï¼Œä½†å°åœ–åƒç©ºé–“ä¸æ•æ„Ÿã€‚
    - **CNN** é€éå·ç©å±¤ç²å¾—ã€è¦–è¦ºã€ï¼Œèƒ½æœ‰æ•ˆè™•ç†åœ–åƒï¼Œæˆç‚ºä»Šå¤©æœ€ä¸»æµçš„å½±åƒ AIã€‚
    - åƒ ResNet-101 æˆ– EfficientNet é€™äº›å¼·å¤§çš„æ¨¡å‹ï¼Œéƒ½æ˜¯ CNN çš„ä»£è¡¨ï¼Œå®ƒå€‘åœ¨ã€å·ç©å±¤ã€çš„è¨­è¨ˆä¸Šå„æœ‰å·§å¦™ï¼
    """)
    
    st.balloons()
