import streamlit as st
import torch
from torchvision import models, transforms
from PIL import Image, ImageFilter, ImageOps
import matplotlib.pyplot as plt
import numpy as np
import requests

st.set_page_config(page_title="AI å¤§è…¦å¯¦é©—å®¤", layout="wide")

# --- 1. è¼‰å…¥æ¨¡å‹èˆ‡æ¨™ç±¤ ---
@st.cache_resource
def load_all():
    model = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V1).eval()
    labels = requests.get("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt").text.split("\n")
    return model, labels

model, labels = load_all()

# --- 2. æ•™å­¸ä¸»é¡Œ ---
st.title("ğŸ§© AI è¦–è¦ºé€²åŒ–ï¼šå¾ ANN åˆ° CNN")
st.markdown("""
ç¥ç¶“ç¶²è·¯ï¼ˆANNï¼‰æ˜¯åŸºç¤ï¼Œä½†å®ƒçœ‹åœ–ç‰‡æ™‚åƒåœ¨çœ‹ä¸€å †äº‚ç¢¼ã€‚
ç•¶æˆ‘å€‘çµ¦å®ƒè£ä¸Š**å·ç©å±¤**ï¼Œå®ƒå°±è®Šæˆäº†å…·å‚™ã€è¦–è¦ºç‰¹å¾µæå–ã€èƒ½åŠ›çš„ **CNN**ã€‚
""")

uploaded_file = st.file_uploader("ğŸ“¸ ä¸Šå‚³ä¸€å¼µç…§ç‰‡ï¼Œæ‹†è§£ AI çš„æ€è€ƒé‚è¼¯...", type=["jpg", "png", "jpeg"])

if uploaded_file:
    img = Image.open(uploaded_file).convert('RGB')
    
    # è¦–è¦ºåŒ–å°æ¯”å€
    col_ann, col_cnn = st.columns(2)

    # --- ANN è¦–è¦ºåŒ–ï¼šå‘ˆç¾ã€Œå¤§é›œç‡´ã€é‚è¼¯ ---
    with col_ann:
        st.header("1. ANN é‹ä½œï¼šæ•¸æ“šæ”¤å¹³")
        st.write("**ç‰©ç†å«æ„ï¼šè³‡è¨Šå¤§é›œç‡´**")
        st.write("ANN æœƒæŠŠ 2D åœ–ç‰‡å£“æˆ 1D ç·šæ¢ã€‚å®ƒçœ‹åˆ°çš„æ˜¯æ•¸å­—çš„è·³å‹•ï¼Œè€Œéåœ–åƒã€‚")
        
        # å°‡åœ–ç‰‡è½‰ç‚ºç°éšä¸¦æ”¤å¹³
        img_gray = img.resize((50, 50)).convert('L')
        pixels = np.array(img_gray).flatten()
        
        fig, ax = plt.subplots(figsize=(5, 3))
        ax.plot(pixels[:500], color='gray', linewidth=0.5)
        ax.set_title("ANN çœ¼ä¸­çš„æ•¸å­—æµ")
        st.pyplot(fig)
        st.caption("é€™å°±æ˜¯ ANN é€²è¡Œã€å…¨é€£æ¥æŠ•ç¥¨ã€å‰çš„æ¨£å­ã€‚")

    # --- CNN è¦–è¦ºåŒ–ï¼šå‘ˆç¾ã€Œå·ç©å±¤ã€é‚è¼¯ ---
    with col_cnn:
        st.header("2. CNN é‹ä½œï¼šç‰¹å¾µæå–")
        st.write("**ç‰©ç†å«æ„ï¼šå±€éƒ¨æ¿¾é¡æƒæ**")
        st.write("CNN ä¿ç•™äº†ç©ºé–“é—œä¿‚ã€‚æ¿¾é¡æœƒæ‰¾å‡ºé‚Šç·£å’Œå½¢ç‹€ï¼Œå°±åƒåµæ¢åœ¨æ‰¾ç·šç´¢ã€‚")
        
        # ä¿®æ­£å¾Œçš„ Filter èªæ³•
        cnn_edges = img.convert('L').filter(ImageFilter.FIND_EDGES)
        st.image(cnn_edges, caption="å·ç©å±¤æŠ“å–çš„é‚Šç·£ç‰¹å¾µåœ–", use_container_width=True)

    st.markdown("---")

    # --- 3. èªæ„è³ªè®Šå‘ˆç¾ ---
    st.header("ğŸ—ï¸ å·ç©å±¤çš„ä¸‰éšæ®µè³ªè®Š")
    v1, v2, v3 = st.columns(3)
    
    with v1:
        st.subheader("ç¬¬ä¸€éšæ®µï¼šé‚Šç·£")
        st.image(img.convert('L').filter(ImageFilter.FIND_EDGES), use_container_width=True)
        st.write("æå–åŸºç¤ç·šæ¢èˆ‡æ˜æš—ã€‚")
        
    with v2:
        st.subheader("ç¬¬äºŒéšæ®µï¼šé›¶ä»¶")
        # å¼·åŒ–å°æ¯”æ¨¡æ“¬å±€éƒ¨é›¶ä»¶æå–
        part_view = img.filter(ImageFilter.SHARPEN).convert('RGB')
        st.image(part_view, use_container_width=True)
        st.write("çµ„åˆç·šæ¢ï¼Œèªå‡ºé›¶ä»¶å½¢ç‹€ã€‚")
        
    with v3:
        st.subheader("ç¬¬ä¸‰éšæ®µï¼šèªæ„")
        # ç†±åŠ›åœ–æ¨¡æ“¬ AI æ³¨æ„åŠ›åˆ†ä½ˆ
        heatmap = img.convert('L').resize((14, 14)).resize(img.size, resample=Image.NEAREST)
        heatmap = ImageOps.colorize(heatmap, black="blue", white="red")
        st.image(heatmap, use_container_width=True)
        st.write("æ‹‹æ£„ç´°ç¯€ï¼Œç†è§£ç‰©ä»¶çš„ç©ºé–“é‚è¼¯ã€‚")

    # --- 4. è¾¨è­˜çµæœ ---
    st.markdown("---")
    st.header("ğŸ† æœ€çµ‚åˆ¤æ–·çµæœ")
    preprocess = transforms.Compose([
        transforms.Resize(256), transforms.CenterCrop(224),
        transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    input_t = preprocess(img).unsqueeze(0)
    with torch.no_grad():
        out = model(input_t)
        prob = torch.nn.functional.softmax(out[0], dim=0)
        top_p, top_id = torch.topk(prob, 1)
        st.metric(label="AI èªå‡ºçš„ç‰©ä»¶æ˜¯ï¼š", value=labels[top_id[0]], delta=f"ä¿¡å¿ƒå€¼ {top_p[0]:.2%}")

st.write("---")
st.info("ğŸ’¡ æ¥­ç•Œå¯¦ä¾‹ï¼šåœ¨è‡ªé§•è»Šç³»çµ±ä¸­ï¼ŒCNN è² è²¬å¿«é€ŸæŠ“å–è·¯æ³ç‰¹å¾µï¼›åœ¨é†«ç™‚è¨ºæ–·ä¸­ï¼Œæ·±å±¤çš„ CNNï¼ˆå¦‚ ResNetï¼‰å‰‡è² è²¬ç²¾æº–æ¯”å°è…«ç˜¤ç´‹ç†ã€‚")
